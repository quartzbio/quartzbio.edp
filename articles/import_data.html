<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Importing Data • quartzbio.edp</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Importing Data">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">quartzbio.edp</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.99.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html">Articles</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/r_authentication.html">Authentication</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/quartzbio/quartzbio.edp/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Importing Data</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/quartzbio/quartzbio.edp/blob/main/vignettes/import_data.Rmd" class="external-link"><code>vignettes/import_data.Rmd</code></a></small>
      <div class="d-none name"><code>import_data.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<p>The EDP specializes in harmonizing a variety of data sources through
its robust import system. Importing data is the process of converting a
flat file into a dataset that can be queried in real time. The EDP
supports data in the most common formats, including JSONL, VCF, CSV,
TSV, XML, GTF, and GFF3. Users can contact QuartzBio Support for
assistance with importing many other formats (including custom,
proprietary formats, and unstructured data).</p>
<p>The EDP’s import system automates the traditional ETL (Extract,
Transform, Load) process. The process typically starts by uploading
files into a vault. An import task can then be configured and launched.
The import system automatically handles data extraction (file parsing),
data transformation, data validation, and finally data loading. Users
can refer to the Import Parameters documentation for more information
about configuring optional parameters for data parsing, entity
detection, validation, and annotation.</p>
</div>
<div class="section level2">
<h2 id="supported-formats">Supported Formats<a class="anchor" aria-label="anchor" href="#supported-formats"></a>
</h2>
<p>The following file formats and extensions are supported:</p>
<table class="table">
<colgroup>
<col width="33%">
<col width="22%">
<col width="22%">
<col width="22%">
</colgroup>
<thead><tr class="header">
<th>Name</th>
<th>File Extension</th>
<th>Previewable in EDP?</th>
<th>Transformable into a Dataset?</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Comma Separated Values</td>
<td>.csv</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr class="even">
<td>General Feature Format</td>
<td>.gff3.gz</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr class="odd">
<td>Gene Transfer Format</td>
<td>.gtf</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr class="even">
<td>Hyper Text Markup Language</td>
<td>.html</td>
<td>Y</td>
<td>N</td>
</tr>
<tr class="odd">
<td>JavaScript Object Notation (in JSON Lines format)</td>
<td>.json</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr class="even">
<td>Mutation Annotation Format</td>
<td>.maf</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr class="odd">
<td>Portable Document Format</td>
<td>.pdf</td>
<td>Y</td>
<td>N</td>
</tr>
<tr class="even">
<td>Tab Separated Values</td>
<td>.tsv</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr class="odd">
<td>Unformatted text file</td>
<td>.txt</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr class="even">
<td>Variant Call Format</td>
<td>.vcf</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr class="odd">
<td>Extensible Markup Language</td>
<td>.xml</td>
<td>Y</td>
<td>Y (requires a template)</td>
</tr>
<tr class="even">
<td>Excel</td>
<td>.xlsx/.xsl</td>
<td>Y</td>
<td>Y</td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="reader-parameters">Reader Parameters<a class="anchor" aria-label="anchor" href="#reader-parameters"></a>
</h2>
<p>EDP automatically detects the file format based on the extension,
except for the Nirvana JSON file, and parses the file using a
specialized “reader”. It is possible to manually specify a reader and
modify reader parameters using the reader_params attribute of the
DatasetImport resource.</p>
<table class="table">
<thead><tr class="header">
<th>Reader</th>
<th>Reader name</th>
<th>Extension</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>VCF</td>
<td>vcf</td>
<td>.vcf</td>
</tr>
<tr class="even">
<td>JSONL</td>
<td>json</td>
<td>.json</td>
</tr>
<tr class="odd">
<td>CSV</td>
<td>csv</td>
<td>.csv</td>
</tr>
<tr class="even">
<td>TSV</td>
<td>tsv</td>
<td>.tsv, .txt, .maf</td>
</tr>
<tr class="odd">
<td>XML</td>
<td>XML</td>
<td>.xml</td>
</tr>
<tr class="even">
<td>GTF</td>
<td>gft</td>
<td>.gtf</td>
</tr>
<tr class="odd">
<td>GFF3</td>
<td>gff3</td>
<td>.gff3</td>
</tr>
<tr class="even">
<td>Nirvana</td>
<td>json</td>
<td>nirvana .json</td>
</tr>
<tr class="odd">
<td>Excel</td>
<td>xlsx</td>
<td>.xlsx</td>
</tr>
<tr class="even">
<td>Excel</td>
<td>xls</td>
<td></td>
</tr>
</tbody>
</table>
<p>EDP supports GZip compression for all file types. Gzipped files must
have the .gz file extension in addition to their format extension
(i.e. file.vcf.gz). Users are recommended to compress files with GZip
for faster uploads and imports.</p>
</div>
<div class="section level2">
<h2 id="importing-from-files">Importing from Files<a class="anchor" aria-label="anchor" href="#importing-from-files"></a>
</h2>
<p>The first step to getting data onto EDP is by uploading files into a
vault. Users can refer to the Vaults documentation for more
information.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ibrary</span><span class="op">(</span><span class="va">quartzbio.edp</span><span class="op">)</span></span>
<span><span class="va">vault</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Vault.get_personal_vault.html">Vault.get_personal_vault</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">uploaded_file</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/File_upload.html">File_upload</a></span><span class="op">(</span><span class="va">vault</span><span class="op">$</span><span class="va">id</span>, <span class="st">"local/path/file.vcf.gz"</span>, <span class="st">"/"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Retrieve the file by its full path:</span></span>
<span><span class="va">uploaded_file</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Object.get_by_full_path.html">Object.get_by_full_path</a></span><span class="op">(</span><span class="st">"~/file.vcf.gz"</span><span class="op">)</span></span></code></pre></div>
<p>Once the files have been uploaded, they can be imported into any new
or existing dataset (Learn how to create a dataset). To launch an
import, users can utilize the DatasetImport method. The user will need
to provide the uploaded file and target dataset as inputs. Once the
import has been launched, it is possible to track the progress through
the API on the web interface through the Activity tab.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://quartzbio.github.io/quartzbio.edp/">quartzbio.edp</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">vault</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Vault.get_personal_vault.html">Vault.get_personal_vault</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">dataset_full_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="va">vault</span><span class="op">$</span><span class="va">full_path</span>, <span class="st">"/r_examples/test_dataset"</span>, sep <span class="op">=</span> <span class="st">":"</span><span class="op">)</span></span>
<span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Dataset.get_or_create_by_full_path.html">Dataset.get_or_create_by_full_path</a></span><span class="op">(</span><span class="va">dataset_full_path</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Launch the import</span></span>
<span><span class="va">imp</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DatasetImport.create.html">DatasetImport.create</a></span><span class="op">(</span></span>
<span>  dataset_id <span class="op">=</span> <span class="va">dataset</span><span class="op">$</span><span class="va">id</span>,</span>
<span>  object_id <span class="op">=</span> <span class="va">object</span><span class="op">$</span><span class="va">id</span>,</span>
<span>  commit_mode <span class="op">=</span> <span class="st">"append"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Wait for the import to complete</span></span>
<span><span class="fu"><a href="../reference/Dataset.activity.html">Dataset.activity</a></span><span class="op">(</span><span class="va">dataset</span><span class="op">$</span><span class="va">id</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="importing-from-urls">Importing from URLs<a class="anchor" aria-label="anchor" href="#importing-from-urls"></a>
</h2>
<p>If the files are on a remote server and accessible by URL, they can
be imported using a manifest. A manifest is simply a list of files (URLs
and other attributes) to import:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">source_url</span> <span class="op">&lt;-</span> <span class="st">"https://s3.amazonaws.com/downloads.solvebio.com/demo/interesting-variants.json.gz"</span></span>
<span></span>
<span><span class="va">manifest</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  files <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>url <span class="op">=</span> <span class="va">source_url</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Once the manifest has been created, it can be imported into any new
or existing dataset. To launch an import, users can employ the
DatasetImport resource, providing the manifest and target dataset as
input. Once the import has been launched it is available to track the
progress through the API or on the web.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://quartzbio.github.io/quartzbio.edp/">quartzbio.edp</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">vault</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Vault.get_personal_vault.html">Vault.get_personal_vault</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">dataset_full_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="va">vault</span><span class="op">$</span><span class="va">full_path</span>, <span class="st">"/r_examples/manifest_dataset"</span>, sep <span class="op">=</span> <span class="st">":"</span><span class="op">)</span></span>
<span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Dataset.get_or_create_by_full_path.html">Dataset.get_or_create_by_full_path</a></span><span class="op">(</span><span class="va">dataset_full_path</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Launch the import</span></span>
<span><span class="va">imp</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DatasetImport.create.html">DatasetImport.create</a></span><span class="op">(</span></span>
<span>  dataset_id <span class="op">=</span> <span class="va">dataset</span><span class="op">$</span><span class="va">id</span>,</span>
<span>  manifest <span class="op">=</span> <span class="va">manifest</span>,</span>
<span>  commit_mode <span class="op">=</span> <span class="st">"append"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Wait for the import to complete</span></span>
<span><span class="fu"><a href="../reference/Dataset.activity.html">Dataset.activity</a></span><span class="op">(</span><span class="va">dataset</span><span class="op">$</span><span class="va">id</span><span class="op">)</span></span></code></pre></div>
<p>The EDP can also pull data from DNAnexus, SevenBridges, and many
other pipelines. Users can contact QuartzBio Support for more
information.</p>
</div>
<div class="section level2">
<h2 id="importing-from-records">Importing from Records<a class="anchor" aria-label="anchor" href="#importing-from-records"></a>
</h2>
<p>The EDP can also import data as a list of records, i.e. a list of
Python dictionaries or R data. Users should note that the EDP supports
only importing up to 5000 records at a time through this method.
Importing from records is most optimal for importing small datasets and
making edits to datasets. For larger imports and transforms, users are
recommended to import from compressed JSONL files.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://quartzbio.github.io/quartzbio.edp/">quartzbio.edp</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">vault</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Vault.get_personal_vault.html">Vault.get_personal_vault</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">dataset_full_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="va">vault</span><span class="op">$</span><span class="va">full_path</span>, <span class="st">"/r_examples/records_dataset"</span>, sep <span class="op">=</span> <span class="st">":"</span><span class="op">)</span></span>
<span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Dataset.get_or_create_by_full_path.html">Dataset.get_or_create_by_full_path</a></span><span class="op">(</span><span class="va">dataset_full_path</span><span class="op">)</span></span>
<span></span>
<span><span class="va">records</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>gene <span class="op">=</span> <span class="st">"CFTR"</span>, importance <span class="op">=</span> <span class="fl">1</span>, sample_count <span class="op">=</span> <span class="fl">2104</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>gene <span class="op">=</span> <span class="st">"BRCA2"</span>, importance <span class="op">=</span> <span class="fl">1</span>, sample_count <span class="op">=</span> <span class="fl">1391</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>gene <span class="op">=</span> <span class="st">"CLIC2"</span>, importance <span class="op">=</span> <span class="fl">5</span>, sample_count <span class="op">=</span> <span class="fl">14</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">imp</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DatasetImport.create.html">DatasetImport.create</a></span><span class="op">(</span></span>
<span>  dataset_id <span class="op">=</span> <span class="va">dataset</span><span class="op">$</span><span class="va">id</span>,</span>
<span>  data_records <span class="op">=</span> <span class="va">records</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="transforming-imported-data">Transforming Imported Data<a class="anchor" aria-label="anchor" href="#transforming-imported-data"></a>
</h2>
<p>Imported data can be transformed (fields added or edited) by
providing a list of fields to the target_fields parameter. Expressions
can be used to dynamically modify the data as it is imported, making it
possible to</p>
<ul>
<li>Modify data types (numbers to strings or vice-versa)</li>
<li>Add new fields with static or dynamic content</li>
<li>Format strings and dates to clean the data</li>
<li>Merge data from datasets</li>
</ul>
<p>The following example imports a list of records and transforms the
contents in a single step:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://quartzbio.github.io/quartzbio.edp/">quartzbio.edp</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">vault</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Vault.get_personal_vault.html">Vault.get_personal_vault</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">dataset_full_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="va">vault</span><span class="op">$</span><span class="va">full_path</span>, <span class="st">"/r_examples/transform_dataset"</span>, sep <span class="op">=</span> <span class="st">":"</span><span class="op">)</span></span>
<span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Dataset.get_or_create_by_full_path.html">Dataset.get_or_create_by_full_path</a></span><span class="op">(</span><span class="va">dataset_full_path</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The original records</span></span>
<span><span class="va">records</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"Francis Crick"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"James Watson"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"Rosalind Franklin"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The transforms to apply through "target_fields"</span></span>
<span><span class="co"># Compute the first and last names.</span></span>
<span><span class="va">target_fields</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    name <span class="op">=</span> <span class="st">"first_name"</span>,</span>
<span>    description <span class="op">=</span> <span class="st">"Adds a first name column based on name column"</span>,</span>
<span>    data_type <span class="op">=</span> <span class="st">"string"</span>,</span>
<span>    expression <span class="op">=</span> <span class="st">"record.name.split(' ')[0]"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    name <span class="op">=</span> <span class="st">"last_name"</span>,</span>
<span>    description <span class="op">=</span> <span class="st">"Adds a last name column based on name column"</span>,</span>
<span>    data_type <span class="op">=</span> <span class="st">"string"</span>,</span>
<span>    expression <span class="op">=</span> <span class="st">"record.name.split(' ')[-1]"</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Import and transform the records</span></span>
<span><span class="va">imp</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DatasetImport.create.html">DatasetImport.create</a></span><span class="op">(</span></span>
<span>  dataset_id <span class="op">=</span> <span class="va">dataset</span><span class="op">$</span><span class="va">id</span>,</span>
<span>  data_records <span class="op">=</span> <span class="va">records</span>,</span>
<span>  target_fields <span class="op">=</span> <span class="va">target_fields</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Wait until import is completed</span></span>
<span><span class="fu"><a href="../reference/Dataset.activity.html">Dataset.activity</a></span><span class="op">(</span><span class="va">dataset</span><span class="op">$</span><span class="va">id</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="../reference/Dataset_query.html">Dataset_query</a></span><span class="op">(</span><span class="va">dataset</span><span class="op">$</span><span class="va">id</span>, exclude_fields <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"_id"</span>, <span class="st">"_commit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Output:</span></span>
<span><span class="co">#  first_name last_name              name</span></span>
<span><span class="co">#  1    Francis     Crick     Francis Crick</span></span>
<span><span class="co">#  2      James    Watson      James Watson</span></span>
<span><span class="co">#  3   Rosalind  Franklin Rosalind Franklin</span></span></code></pre></div>
<p>Existing imported data can also be modified by using migrations. This
allows a user to add a column, modify data within a column, or remove a
column.</p>
</div>
<div class="section level2">
<h2 id="validating-imported-data">Validating Imported Data<a class="anchor" aria-label="anchor" href="#validating-imported-data"></a>
</h2>
<p>When importing data, every record is validated to ensure it can be
committed into a Dataset. Validation compares the schema of existing
Dataset fields with the values of incoming data and issues validation
errors if the Dataset field schema does not match the incoming value.
Validation can also issue warnings.</p>
<p>During validation, a field’s data_type and is_list values are
checked. All records are evaluated (although users may override this to
fail fast on the first error). A commit will not be created if there are
any validation errors.</p>
<p>The following settings can be passed to the validation_params
field.</p>
<ul>
<li>disable - (boolean) default False - Disables validation
completely</li>
<li>raise_on_errors - (boolean) default False - Will fail the import on
first validation error encountered.</li>
<li>strict_validation - (boolean) default False - Will upgrade all
validation warnings to errors.</li>
<li>allow_new_fields - (boolean) default False - If strict validation is
True, will still allow new fields to be added</li>
</ul>
<p>The following example fails an import as soon as invalid data is
detected:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">imp</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DatasetImport.create.html">DatasetImport.create</a></span><span class="op">(</span></span>
<span>  dataset_id <span class="op">=</span> <span class="va">dataset</span><span class="op">$</span><span class="va">id</span>,</span>
<span>  object_id <span class="op">=</span> <span class="va">object</span><span class="op">$</span><span class="va">id</span>,</span>
<span>  validation_params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    raise_on_errors <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The following example disables validation from running, which can
improve import performance.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">imp</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DatasetImport.create.html">DatasetImport.create</a></span><span class="op">(</span></span>
<span>  dataset_id <span class="op">=</span> <span class="va">dataset</span><span class="op">$</span><span class="va">id</span>,</span>
<span>  object_id <span class="op">=</span> <span class="va">object</span><span class="op">$</span><span class="va">id</span>,</span>
<span>  validation_params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    disable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="committing-imported-data">Committing Imported Data<a class="anchor" aria-label="anchor" href="#committing-imported-data"></a>
</h2>
<p>Once data has been extracted from files, transformed, and validated,
it will be automatically indexed (“committed”) into EDP’s datastore.
Dataset commits represent all changes made to the target dataset by the
import process. Four commit modes can be selected depending on the
scenario: append (default), overwrite, upsert, and delete. The commit
mode can be specified when creating the DatasetImport using the
commit_mode parameter.</p>
<div class="section level3">
<h3 id="append-default">append (default)<a class="anchor" aria-label="anchor" href="#append-default"></a>
</h3>
<p>Append mode always adds records to the dataset. Imported record IDs
(the _id field) will be overwritten with unique values. Only append
commits can be rolled back at this time.</p>
</div>
<div class="section level3">
<h3 id="overwrite">overwrite<a class="anchor" aria-label="anchor" href="#overwrite"></a>
</h3>
<p>Overwrite mode requires that each record have a value in the _id
field. Existing records with the same _id are overwritten
completely.</p>
</div>
<div class="section level3">
<h3 id="upsert">upsert<a class="anchor" aria-label="anchor" href="#upsert"></a>
</h3>
<p>Upsert mode merges imported records with existing records, based on
the value of their _id field. Object fields are merged, scalar fields
(such as integers and strings) are overwritten, and new fields are
added. List fields are completely overwritten regardless of the data
type.</p>
<div class="section level4">
<h4 id="delete">delete<a class="anchor" aria-label="anchor" href="#delete"></a>
</h4>
<p>Delete mode is a special case that deletes existing dataset records
based on their _id field.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="performance-tips">Performance Tips<a class="anchor" aria-label="anchor" href="#performance-tips"></a>
</h2>
<p>Below are some tips for improving the performance of dataset
imports.</p>
<div class="section level4">
<h4 id="disable-data-validation">Disable Data validation<a class="anchor" aria-label="anchor" href="#disable-data-validation"></a>
</h4>
<p>Data validation is enabled by default when running imports or
migrations. This is used for data type checking on each record that is
processed. Disabling this will provide a per-record performance
improvement, translating to substantial time savings for large
datasets.</p>
</div>
<div class="section level4">
<h4 id="dataset-capacity">Dataset Capacity<a class="anchor" aria-label="anchor" href="#dataset-capacity"></a>
</h4>
<p>For many simultaneous imports, use a larger dataset capacity.
Simultaneous imports have a high upper limit (50+) but simultaneous
commits are throttled. Every import spawns a commit that does the actual
indexing of the data. small capacity datasets allow a single running
commit per dataset at a time, the medium allows 2 simultaneous commits,
and large allows 3 simultaneous commits. Commits will remain queued
until running ones are completed.</p>
<p>Indexing operations and query operations are also faster for
larger-capacity datasets. If it is expected a dataset to be queried at
high frequency, then we recommend using a larger dataset. If the dataset
already exists, copy the dataset into a medium or large dataset.</p>
</div>
<div class="section level4">
<h4 id="optimize-expensive-expressions">Optimize “expensive” Expressions<a class="anchor" aria-label="anchor" href="#optimize-expensive-expressions"></a>
</h4>
<p>Some dataset field expressions are more expensive than others.
Dataset query expressions can be sped up by applying exact filters,
using fields to only pull back the fields that are needed, or using
dataset_count() if the length is what is needed.</p>
</div>
</div>
<div class="section level2">
<h2 id="api-endpoints">API Endpoints<a class="anchor" aria-label="anchor" href="#api-endpoints"></a>
</h2>
<p>Methods do not accept URL parameters or request bodies unless
specified. Please note that if your EDP endpoint is
sponsor.edp.aws.quartz.bio, you would use
sponsor.api.edp.aws.quartz.bio.</p>
<div class="section level4">
<h4 id="dataset-imports">Dataset Imports<a class="anchor" aria-label="anchor" href="#dataset-imports"></a>
</h4>
<table class="table">
<colgroup>
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>HTTP Request</th>
<th>Description</th>
<th>Authorization</th>
<th>Response</th>
</tr></thead>
<tbody><tr class="odd">
<td>create</td>
<td>POST <a href="https://" class="external-link uri">https://</a><edp_api_host>/v2/dataset_imports</edp_api_host>
</td>
<td>Create a dataset import for a dataset.</td>
<td>This request requires an authorized user with write permission on
the dataset.</td>
<td>The response returns “HTTP 201 Created”, along with the
DatasetImport resource when successful.</td>
</tr></tbody>
</table>
<p>Request Body:</p>
<p>In the request body, provide an object with the following
properties:</p>
<table class="table">
<colgroup>
<col width="25%">
<col width="25%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th align="center">Property</th>
<th align="center">Value</th>
<th align="center">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">commit_mode</td>
<td align="center">string</td>
<td align="center">A valid commit mode.</td>
</tr>
<tr class="even">
<td align="center">dataset_id</td>
<td align="center">integer</td>
<td align="center">(Optional) The ID of an existing object on EDP.</td>
</tr>
<tr class="odd">
<td align="center">object_id</td>
<td align="center">integer</td>
<td align="center">(Optional) A file manifest (see below).</td>
</tr>
<tr class="even">
<td align="center">manifest</td>
<td align="center">object</td>
<td align="center">(Optional) A vault location to store the export
output (must be an EDP full path).</td>
</tr>
<tr class="odd">
<td align="center">data_records</td>
<td align="center">objects</td>
<td align="center">(Optional) A list of records to import
synchronously.</td>
</tr>
<tr class="even">
<td align="center">description</td>
<td align="center">string</td>
<td align="center">(Optional) A description of this import.</td>
</tr>
<tr class="odd">
<td align="center">entity_params</td>
<td align="center">object</td>
<td align="center">(Optional) Configuration parameters for entity
detection.</td>
</tr>
<tr class="even">
<td align="center">reader_params</td>
<td align="center">object</td>
<td align="center">(Optional) Configuration parameters for readers.</td>
</tr>
<tr class="odd">
<td align="center">validation_params</td>
<td align="center">object</td>
<td align="center">(Optional) Configuration parameters for
validation.</td>
</tr>
<tr class="even">
<td align="center">annotator_params</td>
<td align="center">object</td>
<td align="center">(Optional) Configuration parameters for the
Annotator.</td>
</tr>
<tr class="odd">
<td align="center">include_errors</td>
<td align="center">boolean</td>
<td align="center">If True, a new field (_errors) will be added to each
record containing expression evaluation errors (default: True).</td>
</tr>
<tr class="even">
<td align="center">target_fields</td>
<td align="center">objects</td>
<td align="center">A list of valid dataset fields to create or override
in the import.</td>
</tr>
<tr class="odd">
<td align="center">priority</td>
<td align="center">integer</td>
<td align="center">A priority to assign to this task</td>
</tr>
</tbody>
</table>
<p>When creating a new import, either manifest, object_id or
data_records must be provided. Using a manifest allows you to import a
remote file accessible by HTTP(S), for example:</p>
<pre><code># Example Manifest
{
    "files": [{
        "url": "https://example.com/file.json.gz",
        "name": "file.json.gz",
        "format": "json",
        "size": 100,
        "md5": "",
        "base64_md5": ""
    }]
}</code></pre>
<p>Manifests can include the following parameters:</p>
<table class="table">
<colgroup>
<col width="25%">
<col width="25%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th align="center">Property</th>
<th align="center">Value</th>
<th align="center">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">url</td>
<td align="center">string</td>
<td align="center">A publicly accessible URL pointing to a file to
import into EDP. You must pass a URL or an object_id.</td>
</tr>
<tr class="even">
<td align="center">object_id</td>
<td align="center">long</td>
<td align="center">The ID of an existing object on EDP. You must pass an
object_id or a URL.</td>
</tr>
<tr class="odd">
<td align="center">name</td>
<td align="center">string</td>
<td align="center">(Optional) The name of the file. If not passed, EDP
will take it from the URL or object.</td>
</tr>
<tr class="even">
<td align="center">format</td>
<td align="center">string</td>
<td align="center">(Optional) The file format of the file. If not
passed, EDP will take it from the URL or object.</td>
</tr>
<tr class="odd">
<td align="center">md5</td>
<td align="center">string</td>
<td align="center">(Optional) The md5 hash of the file contents. If
passed, EDP will validate the file after downloading and fail if
mismatched.</td>
</tr>
<tr class="even">
<td align="center">entity_params</td>
<td align="center">object</td>
<td align="center">(Optional) Configuration parameters for entity
detection.</td>
</tr>
<tr class="odd">
<td align="center">reader_params</td>
<td align="center">object</td>
<td align="center">(Optional) Configuration parameters for readers.</td>
</tr>
<tr class="even">
<td align="center">validation_params</td>
<td align="center">object</td>
<td align="center">(Optional) Configuration parameters for
validation.</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>HTTP Request</th>
<th>Description</th>
<th>Authorization</th>
<th>Response</th>
</tr></thead>
<tbody><tr class="odd">
<td>delete</td>
<td>DELETE <a href="https://" class="external-link uri">https://</a><edp_api_host>/v2/dataset_imports/{ID}</edp_api_host>
</td>
<td>Delete a dataset import.</td>
<td>This request requires an authorized user with write permission on
the dataset.</td>
<td>The response returns “HTTP 200 OK” when successful.</td>
</tr></tbody>
</table>
<p>Deleting dataset imports is not recommended as data provenance will
be lost.</p>
<table class="table">
<colgroup>
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>HTTP Request</th>
<th>Description</th>
<th>Authorization</th>
<th>Response</th>
</tr></thead>
<tbody><tr class="odd">
<td>get</td>
<td>GET <a href="https://" class="external-link uri">https://</a><edp_api_host>/v2/dataset_imports/{ID}</edp_api_host>
</td>
<td>Retrieve metadata about an import.</td>
<td>This request requires an authorized user with read permission on the
dataset.</td>
<td>The response contains a DatasetImport resource.</td>
</tr></tbody>
</table>
<table class="table">
<colgroup>
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>HTTP Request</th>
<th>Description</th>
<th>Authorization</th>
<th>Response</th>
</tr></thead>
<tbody><tr class="odd">
<td>list</td>
<td>GET <a href="https://" class="external-link uri">https://</a><edp_api_host>/v2/datasets/{DATASET_ID}/imports</edp_api_host>
</td>
<td>List the imports associated with a dataset.</td>
<td>This request requires an authorized user with read permission on the
dataset.</td>
<td>The response contains a list of DatasetImport resources.</td>
</tr></tbody>
</table>
<table class="table">
<colgroup>
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>HTTP Request</th>
<th>Description</th>
<th>Authorization</th>
<th>Response</th>
</tr></thead>
<tbody><tr class="odd">
<td>cancel</td>
<td>PUT <a href="https://" class="external-link uri">https://</a><edp_api_host>/v2/dataset_imports/{IMPORT_ID}</edp_api_host>
</td>
<td>Cancel a dataset import.</td>
<td>This request requires an authorized user with write permission on
the dataset.</td>
<td>The response will contain a DatasetImport resource with the status
canceled</td>
</tr></tbody>
</table>
<p>Request Body</p>
<p>In the request body, provide a valid DatasetResource object (see
create above) with status = canceled.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by David Caplan, Karl Forner, QuartzBio.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Last modified: 19-Mar-2025 Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
